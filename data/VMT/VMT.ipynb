{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bb0f283-b0c1-48e0-b7fa-1412e61f0ac6",
   "metadata": {},
   "source": [
    "#### VMT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6a904d-5b6b-4b5a-abd0-b326a9750bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5b9553-2e10-4db4-a03f-2f62b1936af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = Path(\".\")     # folder where *tvt.pdf files are\n",
    "output_csv = \"FHWA_VMT_All.csv\"\n",
    "\n",
    "# month dictionary (case-insensitive)\n",
    "month_map = {\n",
    "    \"jan\": 1, \"feb\": 2, \"mar\": 3, \"apr\": 4, \"may\": 5, \"jun\": 6,\n",
    "    \"jul\": 7, \"aug\": 8, \"sep\": 9, \"sept\": 9, \"oct\": 10, \"nov\": 11, \"dec\": 12\n",
    "}s\n",
    "\n",
    "def extract_month_year_from_filename(filename: str):s    \"\"\"\n",
    "    Robustly extract month and year from filenames like:\n",
    "    25augtvt.pdf, 24SeptTVT.pdf, 23JANTVT.pdf, etc.\n",
    "    \"\"\"\n",
    "    stem = filename.lower()\n",
    "\n",
    "    # year\n",
    "    m = re.match(r\"(\\d{2})\", stem)\n",
    "    if not m:\n",
    "        return None, None\n",
    "    year = 2000 + int(m.group(1))\n",
    "\n",
    "    # month\n",
    "    month_match = re.search(r\"(jan|feb|mar|apr|may|jun|jul|aug|sep|sept|oct|nov|dec)\", stem)\n",
    "    if not month_match:\n",
    "        return year, None  # missing month as NaN \n",
    "\n",
    "    month_str = month_match.group(1)\n",
    "    month = month_map.get(month_str, None)\n",
    "\n",
    "    return year, month\n",
    "\n",
    "\n",
    "def extract_vmt_from_pdf(pdf_path):\n",
    "    year, month = extract_month_year_from_filename(pdf_path.name)\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            # table 5 on page 5\n",
    "            if len(pdf.pages) <= 5:\n",
    "                print(f\"Warning: {pdf_path.name} has fewer than 6 pages.\")\n",
    "                return pd.DataFrame()\n",
    "\n",
    "            text = pdf.pages[5].extract_text()\n",
    "            if not text:\n",
    "                print(f\"Warning: No text extracted from {pdf_path.name} page 6.\")\n",
    "                return pd.DataFrame()\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening {pdf_path.name}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # clean lines\n",
    "    lines = [re.sub(r\"\\s+\", \" \", l.strip()) for l in text.split(\"\\n\") if l.strip()]\n",
    "\n",
    "    # find state table boundaries\n",
    "    try:\n",
    "        start = next(i for i, l in enumerate(lines) if \"Connecticut\" in l)\n",
    "    except StopIteration:\n",
    "        print(f\"Warning: Could not find state start in {pdf_path.name}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    end = next((i for i, l in enumerate(lines) if \"TOTALS\" in l), len(lines))\n",
    "    data_lines = lines[start:end]\n",
    "\n",
    "    # only extract state + VMT\n",
    "    pattern = (\n",
    "        r\"([A-Za-z\\s]+)\\s+\"      \n",
    "        r\"(\\d+|-)\\s+\"             \n",
    "        r\"([\\d,]+)\\s+\"           \n",
    "    )\n",
    "\n",
    "    for line in data_lines:\n",
    "        m = re.match(pattern, line)\n",
    "        if m:\n",
    "            state = m.group(1).strip()\n",
    "            vmt = m.group(3).replace(\",\", \"\")\n",
    "            try:\n",
    "                vmt = float(vmt)\n",
    "            except ValueError:\n",
    "                vmt = None\n",
    "\n",
    "            rows.append({\n",
    "                \"year\": year,\n",
    "                \"month\": month,\n",
    "                \"state\": state,\n",
    "                \"vmt\": vmt\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# loop for all files\n",
    "all_dfs = []\n",
    "for pdf_path in sorted(input_dir.glob(\"*tvt.pdf\")):\n",
    "    df = extract_vmt_from_pdf(pdf_path)\n",
    "    if not df.empty:\n",
    "        all_dfs.append(df)\n",
    "        print(f\"Extracted {pdf_path.name} ({len(df)} rows)\")\n",
    "    else:\n",
    "        print(f\"Skipped {pdf_path.name} (no data extracted)\")\n",
    "\n",
    "# combine and save results\n",
    "if all_dfs:\n",
    "    final = pd.concat(all_dfs, ignore_index=True)\n",
    "    final.to_csv(output_csv, index=False)\n",
    "    print(f\"\\nSaved combined file: {output_csv} ({len(final)} rows)\")\n",
    "else:\n",
    "    print(\"No data extracted from any PDF.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c38d13-3a7c-46a2-ae69-c04b29d6f151",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
